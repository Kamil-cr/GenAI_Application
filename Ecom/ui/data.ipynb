{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Can't add messages to thread_28gxuR6W5VwEsbQe1lCtnvlc while a run run_0tfJeID47VF6XaEh0DOoM1le is active.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 137\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssistant response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Debugging line\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: response}\n\u001b[1;32m--> 137\u001b[0m user \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m user_chat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_28gxuR6W5VwEsbQe1lCtnvlc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI want to order a slogan t-shirt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(user)\n",
      "Cell \u001b[1;32mIn[2], line 66\u001b[0m, in \u001b[0;36muser_chat\u001b[1;34m(thread_id, user_input)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muser_chat\u001b[39m(thread_id: \u001b[38;5;28mstr\u001b[39m, user_input: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 66\u001b[0m     client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     67\u001b[0m         thread_id\u001b[38;5;241m=\u001b[39mthread_id, role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, content\u001b[38;5;241m=\u001b[39muser_input\n\u001b[0;32m     68\u001b[0m     )\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# Run the Assistant\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     run \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mruns\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     72\u001b[0m         thread_id\u001b[38;5;241m=\u001b[39mthread_id, assistant_id\u001b[38;5;241m=\u001b[39massistant_id\n\u001b[0;32m     73\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kamil\\AppData\\Local\\anaconda3\\envs\\myopenai\\Lib\\site-packages\\openai\\resources\\beta\\threads\\messages\\messages.py:92\u001b[0m, in \u001b[0;36mMessages.create\u001b[1;34m(self, thread_id, content, role, file_ids, metadata, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `thread_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthread_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/threads/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthread_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/messages\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m     95\u001b[0m         {\n\u001b[0;32m     96\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: content,\n\u001b[0;32m     97\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: role,\n\u001b[0;32m     98\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: file_ids,\n\u001b[0;32m     99\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    100\u001b[0m         },\n\u001b[0;32m    101\u001b[0m         message_create_params\u001b[38;5;241m.\u001b[39mMessageCreateParams,\n\u001b[0;32m    102\u001b[0m     ),\n\u001b[0;32m    103\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    104\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    105\u001b[0m     ),\n\u001b[0;32m    106\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mThreadMessage,\n\u001b[0;32m    107\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kamil\\AppData\\Local\\anaconda3\\envs\\myopenai\\Lib\\site-packages\\openai\\_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1199\u001b[0m     )\n\u001b[1;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\kamil\\AppData\\Local\\anaconda3\\envs\\myopenai\\Lib\\site-packages\\openai\\_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    890\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    891\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    892\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    893\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    894\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m    895\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kamil\\AppData\\Local\\anaconda3\\envs\\myopenai\\Lib\\site-packages\\openai\\_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    977\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    988\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Can't add messages to thread_28gxuR6W5VwEsbQe1lCtnvlc while a run run_0tfJeID47VF6XaEh0DOoM1le is active.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from app.api.utils.settings import ASSISTANT_ID, OPENAI_API_KEY, TOKEN\n",
    "import requests\n",
    "import json\n",
    "\n",
    "assistant_id = str(ASSISTANT_ID)\n",
    "\n",
    "TOKEN =  \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJrYW1pbCIsImV4cCI6MTcxMzc4MzE4M30.ODEwzOsip8f85lb4p7m67LGFUctnqqmfgy2EZn1RgiA\"\n",
    "\n",
    "def get_order():\n",
    "    url = \"http://127.0.0.1:8000/api/orders\"\n",
    "    response = requests.get(url, headers={f\"Authorization\": f\"Bearer {TOKEN}\"})\n",
    "    return json.dumps(response.json())\n",
    "\n",
    "def get_products():\n",
    "    url = \"http://127.0.0.1:8000/api/products\"\n",
    "    response = requests.get(url)\n",
    "    return json.dumps(response.json())\n",
    "\n",
    "def post_cart(product_id, quantity, size):\n",
    "    url = \"http://127.0.0.1:8000/api/cart\"\n",
    "    response = requests.post(url,json={\"product_id\": product_id, \"qauntity\": quantity, \"size\": size}, headers={f\"Authorization\": f\"Bearer {TOKEN}\"})\n",
    "    return json.dumps(response.json())\n",
    "\n",
    "def update_cart(product_id, quantity, size):\n",
    "    url = \"http://127.0.0.1:8000/api/cart\"\n",
    "    response = requests.patch(url,json={\"product_id\": product_id, \"qauntity\": quantity, \"size\": size}, headers={f\"Authorization\": f\"Bearer {TOKEN}\"})\n",
    "    return json.dumps(response.json())\n",
    "    \n",
    "def delete_cart(product_id, quantity, size):    \n",
    "    url = \"http://127.0.0.1:8000/api/cart\"\n",
    "    response = requests.delete(url,json={\"product_id\": product_id, \"qauntity\": quantity, \"size\": size}, headers={f\"Authorization\": f\"Bearer {TOKEN}\"})\n",
    "    return json.dumps(response.json())\n",
    "\n",
    "def post_order(payment_method, first_name, last_name, address, city, state, contact_number):\n",
    "    url = \"http://127.0.0.1:8000/api/order\"\n",
    "    response = requests.post(url,json={\"payment_method\": payment_method, \"first_name\": first_name, \"last_name\": last_name, \"address\": address, \"city\": city, \"state\": state, \"contact_number\": contact_number}, headers={f\"Authorization\": f\"Bearer {TOKEN}\"})\n",
    "    return json.dumps(response.json())\n",
    "\n",
    "def update_order(payment_method, first_name, last_name, address, city, state, contact_number, order_id, order_status):\n",
    "    url = \"http://127.0.0.1:8000/api/order\"\n",
    "    response = requests.patch(url,json={\"order_id\": order_id, \"order_status\": order_status,\"payment_method\": payment_method, \"first_name\": first_name, \"last_name\": last_name, \"address\": address, \"city\": city, \"state\": state, \"contact_number\": contact_number}, headers={f\"Authorization\": f\"Bearer {TOKEN}\"})\n",
    "    return json.dumps(response.json())\n",
    "\n",
    "def cancel_order(order_id, order_status):\n",
    "    url = \"http://127.0.0.1:8000/api/order\"\n",
    "    response = requests.delete(url,json={\"order_id\": order_id, \"order_status\": order_status}, headers={f\"Authorization\": f\"Bearer {TOKEN}\"})\n",
    "    return json.dumps(response.json())\n",
    "\n",
    "available_functions = {\n",
    "    \"get_order\": get_order,\n",
    "    \"get_products\": get_products,\n",
    "    \"post_cart\": post_cart,\n",
    "    \"update_cart\": update_cart,\n",
    "    \"delete_cart\": delete_cart,\n",
    "    \"post_order\": post_order,\n",
    "    \"update_order\": update_order,\n",
    "    \"cancel_order\": cancel_order\n",
    "}\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "async def user_chat(thread_id: str, user_input: str):\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread_id, role=\"user\", content=user_input\n",
    "    )\n",
    "\n",
    "    # Run the Assistant\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread_id, assistant_id=assistant_id\n",
    "    )\n",
    "\n",
    "    # Check if the Run requires action (function call)\n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)\n",
    "\n",
    "        # Add run steps retrieval here\n",
    "        run_steps = client.beta.threads.runs.steps.list(thread_id=thread_id, run_id=run.id)\n",
    "        print(\"Run Steps:\", run_steps)\n",
    "\n",
    "        if run.status == \"requires_action\":\n",
    "            tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "            tool_outputs = []\n",
    "\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                if function_name in available_functions:\n",
    "                    function_to_call = available_functions[function_name]\n",
    "                    response = function_to_call(**function_args)\n",
    "                    tool_outputs.append({\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"output\": response,\n",
    "                    })\n",
    "\n",
    "            # Submit tool outputs and update the run\n",
    "            client.beta.threads.runs.submit_tool_outputs(\n",
    "                thread_id=thread_id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=tool_outputs\n",
    "            )\n",
    "\n",
    "        elif run.status == \"completed\":\n",
    "            # List the messages to get the response\n",
    "            messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "            for message in messages.data:\n",
    "                role_label = \"User\" if message.role == \"user\" else \"Assistant\"\n",
    "                message_content = message.content[0].text.value\n",
    "                print(f\"{role_label}: {message_content}\\n\")\n",
    "                return message_content\n",
    "            break  # Exit the loop after processing the completed run\n",
    "\n",
    "        elif run.status == \"failed\":\n",
    "            print(\"Run failed.\")\n",
    "            break\n",
    "\n",
    "        elif run.status in [\"in_progress\", \"queued\"]:\n",
    "            print(f\"Run is {run.status}. Waiting...\")\n",
    "            time.sleep(5)  # Wait for 5 seconds before checking again\n",
    "\n",
    "        else:\n",
    "            print(f\"Unexpected status: {run.status}\")\n",
    "            break\n",
    "        \n",
    "        await asyncio.sleep(1)   # Wait for a second before checking again\n",
    "\n",
    "    # Retrieve and return the latest message from the assistant\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    response = messages.data[0].content[0].text.value\n",
    "\n",
    "    print(f\"Assistant response: {response}\")  # Debugging line\n",
    "    return {\"response\": response}\n",
    "\n",
    "user = await user_chat(\"thread_28gxuR6W5VwEsbQe1lCtnvlc\", \"I want to order a slogan t-shirt\")\n",
    "print(user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myopenai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
